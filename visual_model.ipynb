{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO80U/fkFn/YO2ViQhxwKUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janwaelty/Master-Thesis/blob/main/visual_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Networks and the Art Market: A Deep Learning Approach to Valuation**\n"
      ],
      "metadata": {
        "id": "8oocVS2jJf51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Define source and destination paths\n",
        "source_path = \"/content/drive/My Drive/Colab Notebooks/visual_model.ipynb\"\n",
        "destination_path = \"/content/drive/My Drive/visual_model.ipynb\"\n",
        "\n",
        "# Check if the source file exists before moving\n",
        "if os.path.exists(source_path):\n",
        "  # Move the file\n",
        "  shutil.move(source_path, destination_path)\n",
        "  print(f\"Notebook moved to: {destination_path}\")\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.stats import linregress\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "!cp /content/drive/My\\ Drive/data_preprocess.py /content/\n",
        "\n",
        "from data_preprocess import (\n",
        "    data_split as data_split,\n",
        "    fit_visualization as fit_visualization,\n",
        "    repeated_to_single_transactions as repeated_to_single_transactions,\n",
        "    one_hot as one_hot,\n",
        "    standardization as standardization,\n",
        "    data_filter as data_filter,\n",
        "    add_prev_avg_price as add_prev_avg_price,\n",
        "    standardization as standardization,\n",
        "    load_image_data as load_image_data,\n",
        "    check_image_existence as check_image_existence,\n",
        "    filter_data_for_missing_images as filter_data_for_missing_images,\n",
        "    resnet_transform as resnet_transform\n",
        ")"
      ],
      "metadata": {
        "id": "rMXm7w_zJoNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2766f82-1dcd-4e95-9276-0b15c49bbc69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MixedTransactionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, base_dir = \"/content/data\", transform=resnet_transform()):\n",
        "        # Store the image paths first, and drop 'image_url' before converting other data\n",
        "        self.image_paths = [os.path.join(base_dir, path.lstrip('/')) for path in X['image_url'].dropna()]\n",
        "\n",
        "        # Drop 'image_url' column, then convert the remaining numerical columns to float32\n",
        "        X = X.drop(columns=['image_url'])\n",
        "        self.X = X.reset_index(drop=True).values.astype('float32')\n",
        "        self.y = y.reset_index(drop=True).values.astype('float32')  # Convert y to numpy array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get numerical features (X) and target values (y)\n",
        "        x = torch.tensor(self.X[index], dtype=torch.float32)\n",
        "        y = torch.tensor(self.y[index], dtype=torch.float32)\n",
        "\n",
        "        # Get the image path (image_url) and open the image\n",
        "        image = Image.open(self.image_paths[index])\n",
        "\n",
        "        #print(f\"Image shape before transform: {image.size}\")  # Print the image size (W, H) before transform\n",
        "\n",
        "        # Apply any transformations if provided (resize, normalization, etc.)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #print(f\"Image shape after transform: {image.shape}\")  # Print the image shape after transform (should be [3, 224, 224])\n",
        "\n",
        "        return x, image, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_dataloaders(X_train, X_test, y_train, y_test, base_dir,  batch_size=128):\n",
        "    # Create the training dataset and dataloader\n",
        "    train_dataset = MixedTransactionDataset(X_train, y_train,  transform=resnet_transform())\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=2,drop_last=True)\n",
        "    # Create the testing dataset and dataloader\n",
        "    test_dataset = MixedTransactionDataset(X_test, y_test,  transform = resnet_transform())\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,  num_workers=2,drop_last=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "class Numerical_Model(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(Numerical_Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)  # Lower dropout\n",
        "        self.leaky_relu = nn.LeakyReLU(0.01)  # Leaky ReLU instead of ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)  # No activation for regression\n",
        "        return x\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.numerical_model = Numerical_Model(in_features)\n",
        "        image_model = torchvision.models.resnet50(weights=\"DEFAULT\")\n",
        "        num_features = image_model.fc.in_features\n",
        "        image_model.fc = nn.Linear(num_features, 10)\n",
        "        self.image_model = image_model\n",
        "        self.fc1 = nn.Linear(20, 1)  # Assuming the final combined features are of size 20 (10 from each model)\n",
        "\n",
        "    def forward(self, numerical_input, image_input):\n",
        "        # Get features from the numerical model\n",
        "        num_features = self.numerical_model(numerical_input)\n",
        "\n",
        "        img_features = self.image_model(image_input)\n",
        "\n",
        "        combined = torch.cat((num_features, img_features), dim=1)\n",
        "\n",
        "        # Final fully connected layer\n",
        "        output = self.fc1(combined)\n",
        "        return output\n",
        "\n",
        "\n",
        "def train(network, trainloader, testloader, epochs=100, eta=0.001):\n",
        "    optimizer = torch.optim.Adam(network.parameters(), lr=eta, weight_decay=1e-5)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    network = network.to(device)\n",
        "    loss = torch.nn.MSELoss()\n",
        "    val_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Initialize total loss for train and test data\n",
        "        J_train = 0\n",
        "        total_train_samples = 0  # Counter for number of train samples\n",
        "\n",
        "        # Train the network on training data\n",
        "        for num_input, img_input, target in trainloader:\n",
        "          network.train()\n",
        "          optimizer.zero_grad()\n",
        "          num_input, img_input, target = num_input.to(device), img_input.to(device), target.to(device)\n",
        "\n",
        "          prediction = network(num_input, img_input)\n",
        "          target = target.view(-1, 1)\n",
        "          J = loss(prediction, target)\n",
        "\n",
        "          J_train += J.item() * num_input.size(0)\n",
        "          total_train_samples += num_input.size(0)\n",
        "\n",
        "          J.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "        # Compute average train loss\n",
        "        avg_train_loss = J_train / total_train_samples\n",
        "\n",
        "        # Test on validation data\n",
        "        J_test = 0\n",
        "        total_test_samples = 0  # Counter for number of test samples\n",
        "        with torch.no_grad():\n",
        "            network.eval()\n",
        "            for num_input, img_input, target in testloader:\n",
        "                num_input, img_input, target = num_input.to(device), img_input.to(device), target.to(device)\n",
        "\n",
        "                prediction = network(num_input, img_input)\n",
        "                target = target.view(-1, 1)\n",
        "                J_test += loss(prediction, target).item() * target.size(0)\n",
        "                total_test_samples += target.size(0)\n",
        "\n",
        "        # Compute the average test loss\n",
        "        avg_test_loss = J_test / total_test_samples\n",
        "\n",
        "        # Print train and test loss for each epoch\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}]',\n",
        "              f'Train loss: {avg_train_loss:.6f}',\n",
        "              f'Test loss: {avg_test_loss:.6f}')\n",
        "\n",
        "    # Save predictions and targets after last epoch\n",
        "    pred, target_vals = [], []\n",
        "    with torch.no_grad():\n",
        "        network.eval()\n",
        "        for num_input, img_input, target in testloader:\n",
        "            prediction = network(num_input.to(device), img_input.to(device))\n",
        "            pred.extend(prediction.view(-1).detach().cpu().numpy())\n",
        "            target_vals.extend(target.view(-1).detach().cpu().numpy())\n",
        "\n",
        "    return network, pred, target_vals\n"
      ],
      "metadata": {
        "id": "BvdRIbG0ZItE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  \"\"\"\n",
        "  # Mount Google Drive\n",
        "  drive.mount('/content/drive')\n",
        "  # Define source and destination paths\n",
        "  source_path = \"/content/drive/My Drive/Colab Notebooks/visual_model.ipynb\"\n",
        "  destination_path = \"/content/drive/My Drive/visual_model.ipynb\"\n",
        "\n",
        "  # Check if the source file exists before moving\n",
        "  if os.path.exists(source_path):\n",
        "    # Move the file\n",
        "    shutil.move(source_path, destination_path)\n",
        "    print(f\"Notebook moved to: {destination_path}\")\n",
        "\n",
        "\n",
        "  artist_data_path= \"/content/drive/My Drive/artist_graph_data.xlsx\"\n",
        "  artwork_numeric_data = pd.read_excel(artist_data_path)\n",
        "\n",
        "  # image data\n",
        "  zip_path = \"/content/drive/My Drive/pic.zip\"\n",
        "  extract_path = \"/content/data\"\n",
        "  load_image_data(zip_path, extract_path)\n",
        "  \"\"\"\n",
        "  # Check for missing images\n",
        "  base_dir = \"/content/data\"\n",
        "  image_paths = artwork_numeric_data['image_url'].values\n",
        "  missing_images = check_image_existence(image_paths, base_dir)\n",
        "  data_filtered = filter_data_for_missing_images(artwork_numeric_data, missing_images, base_dir)\n",
        "  # check functioning of image data after filtering\n",
        "  print(f\"After filtering:{check_image_existence(data_filtered['image_url'],base_dir)} \")\n",
        "\n",
        "\n",
        "  selected_vars =  ['category', 'artist', 'transaction_price', 'height',\n",
        "                  'width', 'medium', 'transaction_house',\n",
        "                    'transaction_year_semi', 'image_url']\n",
        "  one_hot_vars = ['category', 'artist', 'medium', 'transaction_house']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = data_split(data_filtered,\n",
        "                                                   selected_vars,\n",
        "                                                   one_hot_vars,\n",
        "                                                 2020, image_url = True)\n",
        "\n",
        "  train_loader, test_loader = create_dataloaders(X_train, X_test, y_train,\n",
        "                                                 y_test, base_dir)\n",
        "\n",
        "\n",
        "\n",
        "  # Initialize the CombinedModel (subtract 1 for image_url column)\n",
        "\n",
        "  model = CombinedModel(X_train.shape[1]-1)\n",
        "\n",
        "\n",
        "  # Train the model\n",
        "  CombinedModel, prediction_combined_model, target = train(model, train_loader,\n",
        "                                                           test_loader,\n",
        "                                                           epochs = 10)\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"Total test batches: {len(test_loader)}\")\n",
        "  print(f\"Total test samples: {len(y_test)}\")\n",
        "  print(f\"Test data shape : {X_test.shape}\")\n",
        "  print(f\"Train data shape : {X_train.shape}\")\n",
        "  print(\"Std of y_test:\", np.std(y_test))\n",
        "  print(\"Std of predictions:\", np.std(prediction_combined_model))\n",
        "\n",
        "\n",
        "\n",
        "  # Train the model using the training data\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions on the test set\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gOKqadylbp--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "69262973-4be7-41bd-9e1d-1e7bfab50c70"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of nans: 1201\n",
            "missing images: 86\n",
            "number of nans: 0\n",
            "missing images: 0\n",
            "After filtering:[] \n",
            "Epoch [1/10] Train loss: 3.732557 Test loss: 1.661303\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-74a22946ea38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   CombinedModel, prediction_combined_model, target = train(model, train_loader,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                                            \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                                            epochs = 10)\n",
            "\u001b[0;32m<ipython-input-16-951158b9985b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, trainloader, testloader, epochs, eta)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Train the network on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m           \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}