{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBeGiMYm9NyYIeoY8vvCnL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janwaelty/Master-Thesis/blob/main/visual_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Networks and the Art Market: A Deep Learning Approach to Valuation**\n"
      ],
      "metadata": {
        "id": "8oocVS2jJf51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.stats import linregress\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torchvision import datasets, transforms\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Define source and destination paths\n",
        "source_path = \"/content/drive/My Drive/Colab Notebooks/visual_model.ipynb\"\n",
        "destination_path = \"/content/drive/My Drive/visual_model.ipynb\"\n",
        "\n",
        "  # Check if the source file exists before moving\n",
        "if os.path.exists(source_path):\n",
        "  # Move the file\n",
        "  shutil.move(source_path, destination_path)\n",
        "  print(f\"Notebook moved to: {destination_path}\")\n",
        "\n",
        "!cp /content/drive/My\\ Drive/data_preprocess.py /content/\n",
        "\n",
        "from data_preprocess import (\n",
        "    data_split as data_split,\n",
        "    fit_visualization as fit_visualization,\n",
        "    repeated_to_single_transactions as repeated_to_single_transactions,\n",
        "    one_hot as one_hot,\n",
        "    standardization as standardization,\n",
        "    data_filter as data_filter,\n",
        "    add_prev_avg_price as add_prev_avg_price,\n",
        "    standardization as standardization\n",
        ")\n",
        "\n",
        "\n",
        "!cp /content/drive/My\\ Drive/image_preprocess.py /content/\n",
        "\n",
        "from image_preprocess import (\n",
        "    load_image_data as load_image_data,\n",
        "    check_image_existence as check_image_existence,\n",
        "    filter_data_for_missing_images as filter_data_for_missing_images,\n",
        "    resnet_transform as resnet_transform\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMXm7w_zJoNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc72c2bb-cd61-49b9-e0ba-69270461e9b0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "class MixedTransactionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, base_dir,, transform=None):\n",
        "        # Ensure numerical data is in float32 format\n",
        "        self.X = X.reset_index(drop=True).values.astype('float32')  # Convert X to numpy array\n",
        "        self.y = y.reset_index(drop=True).values.astype('float32')  # Convert y to numpy array\n",
        "        self.image_paths = [os.path.join(base_dir, path.lstrip('/')) for path in X['image_url'].dropna()]\n",
        "        self.X = X.drop(columns=['image_url']).reset_index(drop=True).values.astype('float32')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get numerical features (X) and target values (y)\n",
        "        x = torch.tensor(self.X[index], dtype=torch.float32)\n",
        "        y = torch.tensor(self.y[index], dtype=torch.float32)\n",
        "\n",
        "        # Get the image path (image_url) and open the image\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Apply any transformations if provided (resize, normalization, etc.)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return x, y, image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "\n",
        "def create_dataloaders(X_train, X_test, y_train, y_test, base_dir,  batch_size=32):\n",
        "    # Create the training dataset and dataloader\n",
        "    train_dataset = MixedTransactionDataset(X_train, y_train, transform=resnet_transform())\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    # Create the testing dataset and dataloader\n",
        "    test_dataset = MixedTransactionDataset(X_test, y_test)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "BvdRIbG0ZItE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load zip file with images**"
      ],
      "metadata": {
        "id": "w110-grDq7OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == 'main':\n",
        "  # Mount Google Drive\n",
        "  drive.mount('/content/drive')\n",
        "  # Define source and destination paths\n",
        "  source_path = \"/content/drive/My Drive/Colab Notebooks/visual_model.ipynb\"\n",
        "  destination_path = \"/content/drive/My Drive/visual_model.ipynb\"\n",
        "\n",
        "  # Check if the source file exists before moving\n",
        "  if os.path.exists(source_path):\n",
        "    # Move the file\n",
        "    shutil.move(source_path, destination_path)\n",
        "    print(f\"Notebook moved to: {destination_path}\")\n",
        "\n",
        "  artist_data_path= \"/content/drive/My Drive/artist_graph_data.xlsx\"\n",
        "  artwork_numeric_data = pd.read_excel(artist_data_path)\n",
        "\n",
        "\n",
        "  selected_vars =  ['category', 'artist', 'transaction_price', 'height',\n",
        "                  'width', 'medium', 'transaction_house',\n",
        "                    'transaction_year_semi', 'image_url']\n",
        "  one_hot_vars = ['category', 'artist', 'medium', 'transaction_house']\n",
        "\n",
        "\n",
        "\n",
        "  X_train, X_test, y_train, y_test = data_split(artwork_numeric_data,\n",
        "                                                   selected_vars,\n",
        "                                                   one_hot_vars, 2020)\n"
      ],
      "metadata": {
        "id": "gOKqadylbp--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}